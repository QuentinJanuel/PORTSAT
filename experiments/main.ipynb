{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argumentation framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.iccma.index import get_graphs\n",
    "from utils.test.index import test\n",
    "\n",
    "TESTING = False\n",
    "\n",
    "if TESTING:\n",
    "    graphs = get_graphs([\n",
    "        (\"scc\", \"small\"),\n",
    "        (\"gr\", \"small\"),\n",
    "        (\"st\", \"small\"),\n",
    "    ])\n",
    "    # Complete, stable and preferred\n",
    "    test(\n",
    "        iccma_graphs=graphs,\n",
    "        solvers=[\"minisat\", \"manysat\", \"maplesat\", \"glucose\"],\n",
    "        semantics=[\"CO\", \"ST\", \"PR\"],\n",
    "        tasks=[\"SE\", \"EE\"],\n",
    "        timeout=100,  # seconds\n",
    "    )\n",
    "    # Grounded (must not set the solvers)\n",
    "    test(\n",
    "        iccma_graphs=graphs,\n",
    "        solvers=[],\n",
    "        semantics=[\"GR\"],\n",
    "        tasks=[\"SE\", \"EE\"],\n",
    "        timeout=1,  # seconds\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipped testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised _ReproducibleRandom with seed 164925917376\n",
      "complete: SE-CO\n",
      "Generation: 100%          \n",
      "Execution: 100%          \n"
     ]
    }
   ],
   "source": [
    "from utils.benchmark.line_graph import bench\n",
    "from utils.problem import Problem, Task, Semantics\n",
    "from typing import List\n",
    "from graphs import graphs\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "TASKS: List[Task] = [\"SE\", \"EE\", \"DC\", \"DS\"]\n",
    "SEMANTICS: List[Semantics] = [\"CO\", \"ST\", \"PR\"]\n",
    "SOLVERS = [\n",
    "    \"minisat\",\n",
    "    \"manysat\",\n",
    "    \"glucose\",\n",
    "    \"maplesat\",\n",
    "]\n",
    "\n",
    "name, graph = list(graphs.items())[0]\n",
    "for task, sem in product(TASKS, SEMANTICS):\n",
    "    problem = Problem(task, sem)\n",
    "    print(f\"{name}: {problem}\")\n",
    "    bench(\n",
    "        graph[\"x_label\"],\n",
    "        graph[\"inputs\"],\n",
    "        graph[\"gen\"],\n",
    "        SOLVERS,\n",
    "        problem,\n",
    "        name,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1af74b6fd445b57231cb1f4d1d189312d2e0b5c21b4c5b7828a9afbf5c2ec803"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
